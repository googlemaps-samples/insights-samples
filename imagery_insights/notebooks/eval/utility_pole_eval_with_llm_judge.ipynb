{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8577eb",
   "metadata": {},
   "source": [
    "# Imagery Insights eval\n",
    "\n",
    "> Add blockquote\n",
    "\n",
    "This notebook demonstrates how to classify images from GCS URIs using the Gemini 1.5 Flash model via Google Cloud's Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852976b",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b816e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-bigquery google-cloud-aiplatform pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd3f5f",
   "metadata": {},
   "source": [
    "## Imports and Vertex AI Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3347679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google import genai\n",
    "from google.genai.types import Content, Part\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import Counter, defaultdict\n",
    "import os, re, base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db579983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "PROJECT_ID = ''  # @param {type:\"string\"}\n",
    "REGION = 'us-central1'      # @param {type:\"string\"}\n",
    "DATASET_ID = '' # @param {type:\"string\"}\n",
    "TABLE_ID = '' # @param {type:\"string\"}\n",
    "QUERY_LIMIT = 10 # @param {type:\"integer\"}\n",
    "MODEL_FLASH = 'gemini-2.5-flash' # @param {type:\"string\"}\n",
    "MODEL_PRO = 'gemini-2.5-pro' # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07d5c8",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize Vertex AI SDK ---\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "print(\"✅ Setup Complete: Libraries installed, configured, and Vertex AI initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f8a0f",
   "metadata": {},
   "source": [
    "## Create vertex client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3bbd7",
   "metadata": {},
   "source": [
    "##Compares two model outputs to see if they are semantically the same.\n",
    "\n",
    "    Args:\n",
    "        output1: The first model's JSON output.\n",
    "        output2: The second model's JSON output.\n",
    "        model_name: The name of the Gemini model to use for comparison.\n",
    "\n",
    "    Returns:\n",
    "        'Yes' if the outputs are semantically the same, 'No' otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d46a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_outputs(output1: str, output2: str) -> str:\n",
    "\n",
    "    comparison_prompt = f\"\"\"You will be provided with two JSON objects. Your task is to determine if they are semantically the same.\n",
    "\n",
    "    Respond with 'SAME' if they are semantically the same, and 'DIFFERENT' if they are not.\n",
    "\n",
    "    Add key points that you saw as different.\n",
    "\n",
    "    JSON 1:\n",
    "    {output1}\n",
    "\n",
    "    JSON 2:\n",
    "    {output2}\n",
    "    \"\"\"\n",
    "    contents = [\n",
    "    comparison_prompt]\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = client.models.generate_content(model=MODEL_FLASH, contents=contents)\n",
    "\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during comparison: {e}\")\n",
    "        return \"Comparison failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a63de1",
   "metadata": {},
   "source": [
    "## Classify image with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3136f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_with_gemini(gcs_uri: str, prompt: str, model_name: str) -> str:\n",
    "    \"\"\"Classifies an image using a Gemini model.\"\"\"\n",
    "\n",
    "    # The 'mime_type' must be passed as a keyword argument.\n",
    "    contents = [\n",
    "    prompt,\n",
    "    Part(file_data={'file_uri': gcs_uri, 'mime_type': 'image/jpeg'})]\n",
    "\n",
    "    response = client.models.generate_content(model=model_name, contents=contents)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for json sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_json(text: str) -> str:\n",
    "    \"\"\"Extracts the JSON string from a text block, even if it's wrapped in markdown.\"\"\"\n",
    "    # Use a regex to find the content between ```json and ```\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # Fallback for just ```\n",
    "    match = re.search(r\"```\\s*(\\{.*?\\})\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    # If no markdown, assume the whole string is the json\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt to extract information from given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You will be provided with a photo of a utility pole.\n",
    "User Input:\n",
    "{\n",
    "photo_of_utility_pole\n",
    "}\n",
    "\n",
    "Follow these instructions to analyze the image:\n",
    "\n",
    "1.  **Analyze the Image:** Carefully examine the provided image. If the image does not clearly show a utility pole, you must return the following JSON object and stop processing:\n",
    "    `{\\\"error\\\": \\\"No utility pole detected in the image.\\\"}`\n",
    "\n",
    "2.  **Identify Key Information:** If a utility pole is present, identify the following information from the image:\n",
    "    *   **Material:** Determine the material the pole is made from (e.g., \\\"wood\\\", \\\"metal\\\", \\\"concrete\\\").\n",
    "    *   **Type:** Determine the primary type of the pole. Choose from: \\\"Street light\\\", \\\"High tension power transmission\\\", \\\"electricity pole\\\", or \\\"other\\\".\n",
    "\n",
    "\n",
    "3.  **Format the Output:** Your response must be the raw JSON object only, without any surrounding text, explanations, or markdown formatting like ```json.\n",
    "\n",
    "**Output Format:**\n",
    "{\n",
    "  \\\"material\\\": \\\"[material]\\\",\n",
    "  \\\"type\\\": \\\"[pole_type]\\\"\n",
    "\n",
    "}\n",
    "\n",
    "**Example:**\n",
    "\n",
    "If the provided image shows a wooden electricity pole with a transformer, power lines, and a street lamp, your output should be:\n",
    "\n",
    "{\n",
    "  \\\"material\\\": \\\"wood\\\",\n",
    "  \\\"type\\\": \\\"electricity pole\\\"\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "try:\n",
    "    # Fetch data from BigQuery\n",
    "    BIGQUERY_SQL_QUERY = f\"\"\"\n",
    "    SELECT\n",
    "      gcs_uri\n",
    "    FROM\n",
    "      `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "      WHERE asset_type = \"ASSET_CLASS_UTILITY_POLE\"\n",
    "\n",
    "    LIMIT {QUERY_LIMIT}\n",
    "    \"\"\"\n",
    "    bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "    eval_dataset = bigquery_client.query(BIGQUERY_SQL_QUERY).to_dataframe()\n",
    "    print(f\"Successfully fetched {len(eval_dataset)} records for evaluation.\")\n",
    "\n",
    "    # Loop through the dataset\n",
    "    for index, row in eval_dataset.iterrows():\n",
    "        uri = row['gcs_uri']\n",
    "        print(f\"--- ({index + 1}/{len(eval_dataset)}) Evaluating {uri} ---\")\n",
    "\n",
    "        flash_classification_raw = classify_image_with_gemini(gcs_uri=uri, prompt=prompt, model_name=MODEL_FLASH)\n",
    "        pro_classification_raw = classify_image_with_gemini(gcs_uri=uri, prompt=prompt, model_name=MODEL_PRO)\n",
    "\n",
    "        # Extract clean JSON strings\n",
    "        flash_classification_str = _extract_json(flash_classification_raw)\n",
    "        pro_classification_str = _extract_json(pro_classification_raw)\n",
    "\n",
    "        # Parse into JSON objects with error handling\n",
    "        try:\n",
    "            flash_output_json = json.loads(flash_classification_str)\n",
    "        except json.JSONDecodeError:\n",
    "            flash_output_json = {'error': 'Failed to parse JSON from flash model.', 'raw_output': flash_classification_raw}\n",
    "\n",
    "        try:\n",
    "            pro_output_json = json.loads(pro_classification_str)\n",
    "        except json.JSONDecodeError:\n",
    "            pro_output_json = {'error': 'Failed to parse JSON from pro model.', 'raw_output': pro_classification_raw}\n",
    "\n",
    "        judgement = judge_outputs(json.dumps(flash_output_json), json.dumps(pro_output_json))\n",
    "\n",
    "        results_list.append({\n",
    "            'gcs_uri': uri,\n",
    "            'flash_output': flash_output_json,\n",
    "            'pro_output': pro_output_json,\n",
    "            'judgement': judgement\n",
    "        })\n",
    "        print(f\"Verdict: {judgement}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    print(\"\\n✅ Evaluation Complete. Analyzing results...\")\n",
    "\n",
    "    agreement_count = results_df['judgement'].str.startswith('SAME').sum()\n",
    "    total_count = len(results_df)\n",
    "    agreement_percentage = (agreement_count / total_count) * 100 if total_count > 0 else 0\n",
    "    print(f\"\\n--- Aggregate Results ---\")\n",
    "    print(f\"Overall Model Agreement: {agreement_percentage:.2f}%\\n\")\n",
    "\n",
    "    disagreements_df = results_df[results_df['judgement'].str.startswith('DIFFERENT')].copy()\n",
    "    print(\"--- Examples of Disagreements ---\")\n",
    "\n",
    "    if not disagreements_df.empty:\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        display(disagreements_df.head(3))\n",
    "    else:\n",
    "        print(\"No disagreements found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the evaluation pipeline: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "utility_pole_basic_analysis_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
