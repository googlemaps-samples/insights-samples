{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w11hv_ICCuXp"
   },
   "source": [
    "# Detect if a lamp is an acquity brand lamp using Supervised fine tuned Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8Ejh5yVQSM0"
   },
   "source": [
    "Initialize the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfFyoRlrGMl9"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This codelab walks you through the process of building a simple image classification system using a pre-trained and then fine-tuned Gemini model. The goal is to accurately identify whether a given lamp image belongs to the \"Acquity\" brand.\n",
    "\n",
    "The process involves:\n",
    "\n",
    "1.  **Loading the pre-trained Gemini model:** We start by initializing the generative AI model.\n",
    "2.  **Preparing the dataset:** You'll need a dataset of lamp images, labeled as either \"Acquity\" or \"Not Acquity\". This dataset will be used for fine-tuning.\n",
    "3.  **Fine-tuning the model:** The codelab will guide you through the steps of fine-tuning the Gemini model on your specific dataset. This process adapts the model's knowledge to better recognize Acquity lamps.\n",
    "4.  **Evaluating the model:** After fine-tuning, we'll test the model's performance on unseen data to assess its accuracy.\n",
    "5.  **Making predictions:** Finally, you'll learn how to use the fine-tuned model to predict whether a new lamp image is an Acquity brand lamp.\n",
    "\n",
    "By the end of this codelab, you will have a working example of how to leverage the power of large language models for specific image classification tasks through supervised fine-tuning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12IeQCoDQQ-F"
   },
   "outputs": [],
   "source": [
    "# ------------ Parameters ------------\n",
    "PROJECT_ID = 'sarthaks-lab' # @param {type:\"string\"}\n",
    "LOCATION = 'us-central1' # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bucket-config"
   },
   "outputs": [],
   "source": [
    "# Provide a bucket name\n",
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "!gsutil ls -b {BUCKET_URI} || gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-upload"
   },
   "outputs": [],
   "source": [
    "# Upload the training data to your bucket\n",
    "!gsutil cp \"/Users/sarthakgy/Desktop/insights-samples/imagery_insights/notebooks/Supervised fine tuning/data/acquity_detector_negative_examples_v2.jsonl\" {BUCKET_URI}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzcKxfEusxltri1ik4Vsm3vK"
   },
   "outputs": [],
   "source": [
    "# Install the necessary library\n",
    "!pip install --upgrade --user --quiet google-genai google-cloud-aiplatform\n",
    "\n",
    "# Import the library\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "# Initialize the Vertex AI SDK and Gen AI Client\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Define the dataset URI and model name\n",
    "dataset_uri = f\"{BUCKET_URI}/data/acquity_detector_negative_examples_v2.jsonl\"\n",
    "tuned_model_display_name = \"Aquity_model_detector_fine_tuned\"\n",
    "base_model = \"gemini-2.5-flash\"\n",
    "\n",
    "training_dataset = {\n",
    "    \"gcs_uri\": dataset_uri,\n",
    "}\n",
    "\n",
    "# Tune a model using `tune` method.\n",
    "sft_tuning_job = client.tunings.tune(\n",
    "    base_model=base_model,\n",
    "    training_dataset=training_dataset,\n",
    "    config=types.CreateTuningJobConfig(\n",
    "        tuned_model_display_name=tuned_model_display_name,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Get the tuning job info.\n",
    "tuning_job = client.tunings.get(name=sft_tuning_job.name)\n",
    "\n",
    "# Status Check\n",
    "print(\"Tuning job created. Waiting for completion...\")\n",
    "# Wait for job completion\n",
    "running_states = [\n",
    "    \"JOB_STATE_PENDING\",\n",
    "    \"JOB_STATE_RUNNING\",\n",
    "]\n",
    "\n",
    "while tuning_job.state.name in running_states:\n",
    "    print(\".\", end=\"\")\n",
    "    tuning_job = client.tunings.get(name=tuning_job.name)\n",
    "    time.sleep(60) # Check every minute\n",
    "\n",
    "print()\n",
    "\n",
    "if tuning_job.state.name == \"JOB_STATE_SUCCEEDED\":\n",
    "    MODEL_ENDPOINT = tuning_job.tuned_model.endpoint\n",
    "    print(f\"Model deployed to endpoint: {MODEL_ENDPOINT}\")\n",
    "else:\n",
    "    print(f\"Tuning job failed with state: {tuning_job.state.name}\")\n",
    "    if hasattr(tuning_job, 'error') and tuning_job.error:\n",
    "        print(f\"Error: {tuning_job.error}\")\n",
    "    # Fallback to backup endpoint from later in the notebook\n",
    "    MODEL_ENDPOINT = \"projects/635092392839/locations/us-central1/endpoints/3000095541712388096\"\n",
    "    print(f\"Using backup endpoint: {MODEL_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-2-3-4-5"
   },
   "source": [
    "## Setup\n",
    "Enable APIs and Set Permissions\n",
    "Enable the Vertex AI API\n",
    "\n",
    "Make sure you have been granted the roles for the GCP project you'll access from this notebook:\n",
    "\n",
    "roles/aiplatform.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-7-8-9-0"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-b-c-d-e"
   },
   "outputs": [],
   "source": [
    "# Updated query to group by asset_id and aggregate all image URIs\n",
    "BIGQUERY_QUERY = \"\"\"\n",
    "    SELECT\n",
    "        asset_id,\n",
    "        ARRAY_AGG(gcs_uris[SAFE_OFFSET(0)]) AS gcs_uris\n",
    "    FROM\n",
    "        `sarthaks-lab.imagery_insights_analysis.utility_pole_evaluations`\n",
    "    WHERE\n",
    "        type='Street light'\n",
    "        AND ARRAY_LENGTH(gcs_uris) > 0\n",
    "    GROUP BY\n",
    "        asset_id\n",
    "    LIMIT 1000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-g-h-i-j"
   },
   "outputs": [],
   "source": [
    "MODEL_ENDPOINT = \"projects/635092392839/locations/us-central1/endpoints/3000095541712388096\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-l-m-n-o"
   },
   "outputs": [],
   "source": [
    "# Updated prompt to be more lenient and ask for model number\n",
    "PROMPT = '''Follow these rules precisely to generate your answer:\n",
    "\n",
    "1.  **Analyze the Input:** Carefully examine the provided Lamp Input. Compare its specific features, design elements, markings, and any visible model numbers against the information in the Acuity Brand Identification Guide.\n",
    "\n",
    "2.  **Generate a Confidence Score:** Based on your analysis, internally generate a confidence score from 0.0 to 1.0 that represents your certainty that the lamp is an Acuity brand product.\n",
    "\n",
    "3.  **Apply Strict Classification Logic:** Use your confidence score to determine your answer according to the following thresholds:\n",
    "    *   **If the score is greater than 0.5:** Your answer is \"Yes\". This indicates a high degree of confidence, requiring a direct match of multiple key features, design language, or a model number consistent with the guide.\n",
    "    *   **If the score is between 0.25 and 0.5 (inclusive):** Your answer is \"Maybe\". This indicates some features align with the guide, but there is not enough evidence for a confident \"Yes\" or \"No\".\n",
    "    *   **If the score is less than 0.25:** Your answer is \"No\". This indicates the lamp has features that contradict the guide, is identifiable as a different brand, or lacks any resemblance to an Acuity product.\n",
    "\n",
    "4.  **Format Your Output:** Your response must strictly follow one of the formats below, based on the answer you determined in the previous step. Do not add any extra text, explanations, or apologies.\n",
    "    *   **For a \"Yes\" answer:**\n",
    "        *   If a model number is visible or mentioned in the Lamp Input, respond with: `Yes. Model Number: [model number]`\n",
    "        *   If no model number is available, respond with: `Yes.`\n",
    "\n",
    "    *   **For a \"Maybe\" answer:**\n",
    "        *   Respond with: `Maybe.`\n",
    "\n",
    "    *   **For a \"No\" answer:**\n",
    "        *   Respond with: `No.`'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-q-r-s-t"
   },
   "outputs": [],
   "source": [
    "NUM_ROWS_TO_PROCESS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-v-w-x-y"
   },
   "outputs": [],
   "source": [
    "# ------------ 1. Fetch data from BigQuery ------------\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Execute the query and load the results into a pandas DataFrame\n",
    "df = client.query(BIGQUERY_QUERY).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-a-b-c-d"
   },
   "outputs": [],
   "source": [
    "# ------------ 2. Initialize Vertex AI and Load Model ------------\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Load the generative model\n",
    "model = GenerativeModel(MODEL_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-f-g-h-i"
   },
   "outputs": [],
   "source": [
    "# ------------ 3. Analyze Images ------------\n",
    "# Create an empty list to store the analysis results\n",
    "analysis_results = []\n",
    "\n",
    "# Create a subset of the DataFrame to process\n",
    "df_to_process = df.head(NUM_ROWS_TO_PROCESS)\n",
    "for index, row in df_to_process.iterrows():\n",
    "    # Get the list of GCS URIs for the asset\n",
    "    image_uris = row['gcs_uris']\n",
    "    asset_id = row['asset_id']\n",
    "    print(f\"Processing asset: {asset_id}\")\n",
    "\n",
    "    if image_uris is not None and len(image_uris) > 0:\n",
    "        try:\n",
    "            # Prepare the content for the model: prompt + all images\n",
    "            content_parts = [PROMPT]\n",
    "            for uri in image_uris:\n",
    "                if uri: # Ensure URI is not None\n",
    "                    content_parts.append(Part.from_uri(uri, mime_type='image/jpeg'))\n",
    "\n",
    "            # Generate content with all images and the prompt\n",
    "            response = model.generate_content(content_parts)\n",
    "            result_text = response.text.strip()\n",
    "            print(f\"  -> Result: {result_text}\")\n",
    "            analysis_results.append(result_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error processing asset: {e}\"\n",
    "            print(f\"  -> {error_message}\")\n",
    "            analysis_results.append(error_message)\n",
    "    else:\n",
    "        no_uri_message = \"No GCS URIs found for this asset.\"\n",
    "        print(f\"  -> {no_uri_message}\")\n",
    "        analysis_results.append(no_uri_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-k-l-m-n"
   },
   "outputs": [],
   "source": [
    "# ------------ 4. Display All Results ------------\n",
    "# Create a new DataFrame with only asset_id and analysis_result\n",
    "results_df = pd.DataFrame({\n",
    "    'asset_id': df_to_process['asset_id'],\n",
    "    'analysis_result': analysis_results\n",
    "})\n",
    "\n",
    "# Display the full DataFrame without filtering\n",
    "print(\"\\n--- Final Results --- Succeeded\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-p-q-r-s"
   },
   "source": [
    "# Task\n",
    "Modify the script to add a print statement inside the main processing loop that prints the `asset_id` of each asset from the `sarthaks-lab.imagery_insights_analysis.utility_pole_evaluations` BigQuery table as it is being analyzed by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-u-v-w-x"
   },
   "source": [
    "# Task\n",
    "Summarize the lamp detection results from the `results_df` DataFrame. The summary should be in a new pandas DataFrame and include the count of 'Yes', 'Maybe', 'No', and 'Error' detections, along with a few sample `asset_id`s for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-z-a-b-c"
   },
   "source": [
    "## Generate Summary of Analysis Results\n",
    "\n",
    "### Subtask:\n",
    "Add a new code cell that processes the `results_df` DataFrame. This code will categorize the results into 'Yes', 'Maybe', 'No', and 'Error', count the items in each category, and retrieve a few sample `asset_id`s. The summary will be displayed in a new, nicely formatted pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-e-f-g-h"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    def categorize_result(result):\n",
    "        if not isinstance(result, str):\n",
    "            return 'Error'\n",
    "        if result.startswith('Yes'):\n",
    "            return 'Yes'\n",
    "        elif result == 'Maybe.':\n",
    "            return 'Maybe'\n",
    "        elif result == 'No.':\n",
    "            return 'No'\n",
    "        else:\n",
    "            return 'Error'\n",
    "\n",
    "    results_df['category'] = results_df['analysis_result'].apply(categorize_result)\n",
    "\n",
    "    summary_df = results_df.groupby('category').agg(\n",
    "        count=('asset_id', 'size'),\n",
    "        sample_assets=('asset_id', lambda x: list(x.head(3)))\n",
    "    ).reset_index()\n",
    "\n",
    "    print(\"\\n--- Analysis Summary ---\")\n",
    "    display(summary_df)\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: The 'results_df' DataFrame is not defined. Please ensure the previous cell has been executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-j-k-l-m"
   },
   "source": [
    "### Important Note on Cell Execution\n",
    "\n",
    "The error `NameError: name 'results_df' is not defined` occurs because the DataFrame `results_df` is created in a previous cell but is not available when the summarization code is run. This can happen if the cells are not run in the correct top-to-bottom order, or if the notebook kernel has been restarted.\n",
    "\n",
    "**To fix this, please ensure you have successfully executed the cell that performs the image analysis and creates the `results_df` DataFrame (the long cell beginning with `from google.cloud import bigquery`) *before* running the final summary cell below.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
