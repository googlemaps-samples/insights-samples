{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bf2e1",
   "metadata": {
    "id": "61d1bfb1"
   },
   "source": [
    "# Measure height of Utility poles with Gemini 2.5 Flash\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook demonstrates how to estimate the height of utility poles using Google Cloud Vertex AI's Gemini 2.5 Flash model and imagery data stored in BigQuery and Google Cloud Storage. The workflow includes querying relevant image observations, grouping images by asset, and applying a multi-image AI-powered analysis to estimate asset heights with structured reasoning.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Access to a Google Cloud Platform (GCP) project with billing enabled.\n",
    "- BigQuery dataset containing utility pole imagery observations.\n",
    "- Google Cloud Storage bucket with image files referenced in BigQuery.\n",
    "- Vertex AI API enabled in your GCP project.\n",
    "- Service account or user credentials with permissions for BigQuery, Vertex AI, and Cloud Storage.\n",
    "- Python 3.8+ environment with internet access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd898ce0",
   "metadata": {
    "id": "ab074d90"
   },
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ed200",
   "metadata": {
    "id": "23f28877"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-bigquery google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa7139",
   "metadata": {
    "id": "de710bd6"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "**Important**: Replace the placeholder values below with your actual GCP Project ID and Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bbae8",
   "metadata": {
    "id": "eefe0d49"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = ''  # @param {type:\"string\"}\n",
    "REGION = 'us-central1'      # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd1fb6",
   "metadata": {
    "id": "64efff2f"
   },
   "source": [
    "## Imports and Vertex AI Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661387e",
   "metadata": {
    "id": "70c48cc9"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from google.cloud import bigquery\n",
    "from google import genai\n",
    "from google.genai.types import Content, Part\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bfc6fe",
   "metadata": {
    "id": "df6a38c6"
   },
   "outputs": [],
   "source": [
    "BIGQUERY_SQL_QUERY = \"\"\"\n",
    "SELECT\n",
    "  t1.gcs_uri,\n",
    "  t1.asset_id,\n",
    "  t1.observation_id,\n",
    "  t1.detection_time,\n",
    "  t1.location\n",
    "FROM\n",
    "  `sarthaks-lab`.`imagery_insights___preview___us`.`all_observations` AS t1\n",
    "WHERE\n",
    "  t1.asset_type = \"ASSET_CLASS_UTILITY_POLE\"\n",
    "  AND t1.asset_id IN (\n",
    "  SELECT\n",
    "    asset_id\n",
    "  FROM\n",
    "    `sarthaks-lab`.`imagery_insights___preview___us`.`all_observations`\n",
    "  WHERE\n",
    "    asset_type = \"ASSET_CLASS_UTILITY_POLE\"\n",
    "  GROUP BY\n",
    "    asset_id\n",
    "  HAVING\n",
    "    COUNT(observation_id) > 1\n",
    "  ORDER BY\n",
    "    asset_id  -- Add an ORDER BY for deterministic LIMIT behavior\n",
    "  LIMIT\n",
    "    10 );\n",
    "\"\"\"\n",
    "\n",
    "# Execute BigQuery Query\n",
    "try:\n",
    "    bigquery_client = bigquery.Client(project=PROJECT_ID)\n",
    "    query_job = bigquery_client.query(BIGQUERY_SQL_QUERY)\n",
    "    query_response_data = [dict(row) for row in query_job]\n",
    "\n",
    "    print(f\"Successfully fetched {len(query_response_data)} observations:\")\n",
    "    for item in query_response_data:\n",
    "        print(f\"Asset ID: {item['asset_id']}, GCS URI: {item['gcs_uri']}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while querying BigQuery: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dbf278",
   "metadata": {
    "id": "b05f2cff"
   },
   "source": [
    "## Step 2: Group Images by Asset\n",
    "\n",
    "### Subtask: Group Images by Asset\n",
    "\n",
    "Add a new cell to process the query results and group the image GCS URIs by their corresponding `asset_id`.\n",
    "**Reasoning**: Now that the data has been successfully queried from BigQuery, I will add a new cell to process the results. This cell will group the GCS URIs of the images by their `asset_id`, preparing the data for the next step where we will process each asset's images together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61cd47",
   "metadata": {
    "id": "126856a8"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Group GCS URIs by asset_id\n",
    "assets = defaultdict(list)\n",
    "if 'query_response_data' in locals():\n",
    "    for item in query_response_data:\n",
    "        asset_id = item.get('asset_id')\n",
    "        gcs_uri = item.get('gcs_uri')\n",
    "        if asset_id and gcs_uri:\n",
    "            assets[asset_id].append(gcs_uri)\n",
    "\n",
    "    # Print the grouped assets\n",
    "    print(f\"Found {len(assets)} unique assets.\")\n",
    "    for asset_id, uris in assets.items():\n",
    "        print(f\"Asset ID: {asset_id}, Observations: {len(uris)}\")\n",
    "else:\n",
    "    print(\"No query response data found to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb531c",
   "metadata": {
    "id": "1ae4daad"
   },
   "source": [
    "## Step 3: Define Height Estimation Function\n",
    "\n",
    "### Subtask: Define Height Estimation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dd53e",
   "metadata": {
    "id": "85b3e0de"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def estimate_asset_height(gcs_uris: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Estimates the height of an asset from a list of images using a Gemini Pro model.\n",
    "    \"\"\"\n",
    "    # Use a powerful model capable of analyzing multiple images and complex instructions.\n",
    "    MODEL = \"gemini-2.5-pro\"\n",
    "\n",
    "    prompt = \"\"\"...\"\"\" # Same long prompt as before\n",
    "\n",
    "    try:\n",
    "        image_parts = [Part(file_data={'file_uri': uri, 'mime_type': 'image/jpeg'}) for uri in gcs_uris]\n",
    "        content = [prompt] + image_parts\n",
    "        responses = client.models.generate_content(content)\n",
    "        response_text = responses.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        result = json.loads(response_text)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error estimating height for URIs {gcs_uris}: {e}\")\n",
    "        return {\n",
    "            \"estimated_height_meters\": None,\n",
    "            \"confidence_score\": \"Error\",\n",
    "            \"reasoning_notes\": str(e)\n",
    "        }\n",
    "\n",
    "print(\"Height estimation function `estimate_asset_height` has been defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2026b5",
   "metadata": {
    "id": "a3b4c5d6"
   },
   "source": [
    "## Step 4: Process Assets and Generate DataFrame\n",
    "\n",
    "### Subtask: Process Assets and Generate DataFrame\n",
    "\n",
    "Iterate through the grouped assets, call the new height estimation function for each, and compile the results (asset ID, number of observations, measured height, and confidence score) into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7f8g9h0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "# Suppress the specific deprecation warning from the Vertex AI SDK\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"This feature is deprecated as of June 24, 2025\")\n",
    "\n",
    "# List to store the results\n",
    "results_data = []\n",
    "\n",
    "print(\"--- Processing Assets and Estimating Height ---\\n\")\n",
    "\n",
    "if 'assets' in locals() and assets:\n",
    "    # Iterate through each asset and its associated image URIs\n",
    "    for asset_id, uris in assets.items():\n",
    "        # Call the height estimation function\n",
    "        estimation_result = estimate_asset_height(uris)\n",
    "\n",
    "        # Extract results for formatted printing\n",
    "        height = estimation_result.get(\"estimated_height_meters\", \"N/A\")\n",
    "        confidence = estimation_result.get(\"confidence_score\", \"N/A\")\n",
    "\n",
    "        # Pretty print the immediate result as requested\n",
    "        print(f\"Asset ID: {asset_id}\\n  - Height: {height} meters\\n  - Confidence: {confidence}\\n\")\n",
    "\n",
    "        # Append the full results to our list for the DataFrame\n",
    "        results_data.append({\n",
    "            \"asset_id\": asset_id,\n",
    "            \"num_observations\": len(uris),\n",
    "            \"estimated_height_meters\": height,\n",
    "            \"confidence_score\": confidence,\n",
    "            \"reasoning_notes\": estimation_result.get(\"reasoning_notes\", \"N/A\")\n",
    "        })\n",
    "\n",
    "    # Create a pandas DataFrame from the results\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "\n",
    "    # Display the final DataFrame in a clean, 'pretty' format\n",
    "    print(\"\\n--- Final Results Summary ---\")\n",
    "    display(results_df)\n",
    "\n",
    "else:\n",
    "    print(\"No assets found to process.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
